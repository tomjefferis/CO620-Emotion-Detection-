,0,1,accuracy,macro avg,weighted avg,name
precision,0.8076923076923077,0.875,0.84,0.8413461538461539,0.8426923076923077,AdaBoost
recall,0.875,0.8076923076923077,0.84,0.8413461538461539,0.84,AdaBoost
f1-score,0.8400000000000001,0.8400000000000001,0.84,0.8400000000000001,0.8400000000000002,AdaBoost
support,24.0,26.0,0.84,50.0,50.0,AdaBoost
precision,0.75,0.8636363636363636,0.8,0.8068181818181819,0.8090909090909091,RFC
recall,0.875,0.7307692307692307,0.8,0.8028846153846154,0.8,RFC
f1-score,0.8076923076923077,0.7916666666666666,0.8,0.7996794871794872,0.7993589743589743,RFC
support,24.0,26.0,0.8,50.0,50.0,RFC
precision,0.22727272727272727,0.32142857142857145,0.28,0.27435064935064934,0.2762337662337662,KNN
recall,0.20833333333333334,0.34615384615384615,0.28,0.27724358974358976,0.28,KNN
f1-score,0.21739130434782608,0.3333333333333333,0.28,0.2753623188405797,0.27768115942028987,KNN
support,24.0,26.0,0.28,50.0,50.0,KNN
precision,0.48,0.0,0.48,0.24,0.2304,SVC
recall,1.0,0.0,0.48,0.5,0.48,SVC
f1-score,0.6486486486486487,0.0,0.48,0.32432432432432434,0.3113513513513514,SVC
support,24.0,26.0,0.48,50.0,50.0,SVC
precision,0.5,0.5384615384615384,0.52,0.5192307692307692,0.52,GPC
recall,0.5,0.5384615384615384,0.52,0.5192307692307692,0.52,GPC
f1-score,0.5,0.5384615384615384,0.52,0.5192307692307692,0.52,GPC
support,24.0,26.0,0.52,50.0,50.0,GPC
precision,0.68,0.72,0.7,0.7,0.7008,DTC
recall,0.7083333333333334,0.6923076923076923,0.7,0.7003205128205128,0.7,DTC
f1-score,0.6938775510204083,0.7058823529411765,0.7,0.6998799519807923,0.7001200480192077,DTC
support,24.0,26.0,0.7,50.0,50.0,DTC
precision,0.2,0.45,0.4,0.325,0.33,MLP
recall,0.08333333333333333,0.6923076923076923,0.4,0.38782051282051283,0.4,MLP
f1-score,0.11764705882352941,0.5454545454545455,0.4,0.3315508021390375,0.3401069518716578,MLP
support,24.0,26.0,0.4,50.0,50.0,MLP
precision,0.75,0.7692307692307693,0.76,0.7596153846153846,0.76,NB
recall,0.75,0.7692307692307693,0.76,0.7596153846153846,0.76,NB
f1-score,0.75,0.7692307692307693,0.76,0.7596153846153846,0.76,NB
support,24.0,26.0,0.76,50.0,50.0,NB
precision,0.48,0.0,0.48,0.24,0.2304,QDA
recall,1.0,0.0,0.48,0.5,0.48,QDA
f1-score,0.6486486486486487,0.0,0.48,0.32432432432432434,0.3113513513513514,QDA
support,24.0,26.0,0.48,50.0,50.0,QDA
